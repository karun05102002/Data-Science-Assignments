{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f0ef9-7cef-4f2a-8c1c-35bf43147278",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4a27e-ebbe-4e73-921d-b65fed6d0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans \n",
    "    Web scraping (or data scraping) is a technique used to collect content and data from the internet.\n",
    "    This data is usually saved in a local file so that it can be manipulated and analyzed as needed.\n",
    "    If you’ve ever copied and pasted content from a website into an Excel spreadsheet, this is essentially what web scraping is, but on a very small scale.\n",
    "\n",
    "    However, when people refer to ‘web scrapers,’ they’re usually talking about software applications.\n",
    "    Web scraping applications (or ‘bots’) are programmed to visit websites, grab the relevant pages and extract useful information.\n",
    "    By automating this process, these bots can extract huge amounts of data in a very short time. \n",
    "    This has obvious benefits in the digital age, when big data—which is constantly updating and changing—plays such a prominent role.\n",
    "\n",
    "    # What kinds of data can you scrape from the web?\n",
    "    \n",
    "    If there’s data on a website, then in theory, it’s scrapable! Common data types organizations collect include images, videos, text, product information, customer sentiments\n",
    "    and reviews (on sites like Twitter, Yell, or Tripadvisor), and pricing from comparison websites.\n",
    "    There are some legal rules about what types of information you can scrape, but we’ll cover these later on.\n",
    "    \n",
    "    # why is it used and where it is used\n",
    "    \n",
    "    Web scraping has countless applications, especially within the field of data analytics. Market research companies use scrapers to pull data from social media or online forums \n",
    "    for things like customer sentiment analysis.Others scrape data from product sites like Amazon or eBay to support competitor analysis. Meanwhile, Google regularly uses web \n",
    "    scraping to analyze, rank, and index their content. Web scraping also allows them to extract information from third-party websites before redirecting it to their own \n",
    "    (for instance, they scrape e-commerce sites to populate Google Shopping).Many companies also carry out contact scraping, which is when they scrape the web for contact\n",
    "    information to be used for marketing purposes. If you’ve ever granted a company access to your contacts in exchange for using their services, then you’ve given them permission \n",
    "    to do just this.There are few restrictions on how web scraping can be used. It’s essentially down to how creative you are and what your end goal is.\n",
    "    From real estate listings, to weather data, to carrying out SEO audits, the list is pretty much endless!\n",
    "    However, it should be noted that web scraping also has a dark underbelly. Bad players often scrape data like bank details or other personal information to conduct fraud,\n",
    "    scams, intellectual property theft, and extortion. \n",
    "    It’s good to be aware of these dangers before starting your own web scraping journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bd62d-0c30-4a4f-bba0-65529ba21f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4cd9c-fbd4-415e-aa17-c56f794fec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Scraping Techniques\n",
    "    Here are a few techniques commonly used to scrape data from websites. In general, all web scraping techniques retrieve content from websites, process it using a scraping engine,\n",
    "    and generate one or more data files with the extracted content.\n",
    "\n",
    "    HTML Parsing\n",
    "        HTML parsing involves the use of JavaScript to target a linear or nested HTML page. It is a powerful and fast method for extracting text and links\n",
    "        (e.g. a nested link or email address), scraping screens and pulling resources.\n",
    "\n",
    "    DOM Parsing\n",
    "        The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth.\n",
    "        DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath. For dynamically generated content, scrapers can embed web browsers like Firefox and Internet Explorer to extract whole web pages (or parts of them).\n",
    "\n",
    "    Vertical Aggregation\n",
    "        Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals. \n",
    "        These are data harvesting platforms that can be run on the cloud and are used to automatically generate and monitor bots for certain verticals with minimal human intervention. Bots are generated according to the information required to each vertical, and their efficiency is determined by the quality of data they extract.\n",
    "    \n",
    "    XPath\n",
    "        XPath is short for XML Path Language, which is a query language for XML documents. XML documents have tree-like structures, so scrapers can use XPath to navigate\n",
    "        through them by selecting nodes according to various parameters. A scraper may combine DOM parsing with XPath to extract whole web pages and publish them on a destination site.\n",
    "\n",
    "    Google Sheets\n",
    "        Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website,\n",
    "        which is useful if they want to extract a specific pattern or data from the website.This command also makes it possible to check if a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1fed9-4a72-4af1-a2ab-92c7e270cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdccc93-4c4e-4283-84e4-d966fae466b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans \n",
    "    Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. Say you’ve found some webpages that display data relevant to your research,\n",
    "    such as date or address information, but that do not provide any way of downloading the data directly. Beautiful Soup helps you pull particular content from a webpage,\n",
    "    remove the HTML markup, and save the information. It is a tool for web scraping that helps you clean up and parse the documents you have pulled down from the web.\n",
    "    The Beautiful Soup documentation will give you a sense of variety of things that the Beautiful Soup library will help with, from isolating titles and links,\n",
    "    to extracting all of the text from the html tags, to altering the HTML within the document you’re working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5ff7a-9a12-435a-8d22-9cc9e4249722",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c498f7-408b-4bfc-9a76-794e93d92637",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans Flask is a lightweight framework to build websites. We will use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape.\n",
    "The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301f4d7-d2b3-495b-9bf1-8cda7e812c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133c190-a145-4260-aae2-a1c52581edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans\n",
    "    AWS console is the web application that allows users to access Amazon web services.Without the console presented in a way users can easily navigate to every Amazon web\n",
    "    service, it will be difficult to have centralized access to all the Amazon web services.\n",
    "    \n",
    "    AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software.\n",
    "    You can quickly model and configure the different stages of a software release process.CodePipeline automates the steps required to release your \n",
    "    software changes continuously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
